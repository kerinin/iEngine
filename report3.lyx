#LyX 1.6.2 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble



\usepackage{amsfonts}
\end_preamble
\use_default_options false
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize 10
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 1.5in
\topmargin 1in
\rightmargin 1.5in
\bottommargin 1.25in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Motivated Decision-Making using Transformation Invariant Probability Estimates
\end_layout

\begin_layout Author
Ryan Michael
\begin_inset Newline newline
\end_inset

 
\family typewriter
kerinin@gmail.com
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Existing Work
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Expectation-maximization_algorithm
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Stationary_process
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Ergodicity
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Mixing_(mathematics)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Lyapunov_exponent
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Recurrence_quantification_analysis
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Recurrence_plot
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_averag
e
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Autocorrelation
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
url{http://en.wikipedia.org/wiki/Linear_discriminant_analysis}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Hidden Markov Model
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% cannot account for future states - only capable of prediction
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% weak, short-term memory
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Box-Jenkins
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% intended for simplistic processes with well-understood stationarity and
 periodicity
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% http://en.wikipedia.org/wiki/Box-Jenkins
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Spectral Analysis
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% assumes some type of frequency-domain decomposition.
  Frequency-domain signal representations do not do a very good job predicting
 time-domain values.
 
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Shrinking-
\begin_inset Formula $\epsilon$
\end_inset

 SVM Regression
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% theoretical foundation weak; only compensates for the relevance of recent
 data.
  See Markhov problem
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
General Overview
\end_layout

\begin_layout Standard
The goal is to create a method of statistical inference capable of processing
 multiple sources of data which are both multi-variate and exhibit transformatio
n-invariant behaviors.
 This type of data is common, and developing a robust method of analysis
 has applications in many domains.
 
\end_layout

\begin_layout Standard
For any estimator of a probability density function, the accuracy (measured
 by the confidence interval) of the estimator can be shown to depend on
 two factors; the number of observations from which the estimates are made
 and the amount of information the estimator is capable of extracting from
 from those observations.
 Existing estimators, such as the Parzen Window estimator extract information
 about the probability of a given point by comparing the distance between
 that point and the set of points previously observed; the greater the number
 of points in that are 'close', the higher the probability.
 It is possible to determine the confidence interval of such an estimator
 using the VC Entropy of the estimating function.
 The VC Entropy of an estimator is based on the number of points which are
 needed to 'cover' the observations with some level of closeness.
 This is to say that if the set of observations contain multiple points
 which are 'close' to each other, the estimator can ignore all but one in
 generating estimates (provided the number of similar points is retained).
\end_layout

\begin_layout Standard
Our task is to develop a set of estimators whose confidence interval is
 less than the confidence interval determined by the VC Entropy, and we
 do so by extending the conceprt of VC Entropy to sets of observations under
 linear transformations.
 Where the VC Entropy is determined by the number of points necessary to
 'cover' the set of observations, we define the Transformation-Invariant
 Entropy (TI Entropy) as the number of 
\emph on
sets of points
\emph default
 necessary to 'cover' the observations under linear transformations.
 In the same way that the VC Entropy is determined by the similarity between
 individual observations, the TI Entropy is determined between sets of observati
ons.
 
\end_layout

\begin_layout Standard
The distance between two points can easily be determined using well-known
 distance metrics; the distance between two sets of points requires that
 we develop a new distance metric.
 This distance metric measures the potential similarity between two sets
 when one has been subjected to some linear transformation.
 For simplicity we will integrate this similarity measure over all possible
 transformations; the resulting similarity measure will describe the net
 similarity of the two sets under 
\emph on
any
\emph default
 linear transformation.
 It is for this reason that we refer to our extension of the VC Entropy
 as Transformation-Invariant.
 It will be shown that the TI Entropy is necessarily less than or equal
 to the VC Entropy, and that as a result the confidence interval of an estimator
 based on the TI-distance between sets of observations is necessarily greater
 than or equal to that of estimators based on the distance between individual
 points.
 
\end_layout

\begin_layout Standard
Because the computational complexity of TI-based estimators is higher than
 that of traditional estimators we will develop search heuristics allowing
 us to confine the TI analysis to subsets of the observations which are
 likely to provide useful results.
 We will develop an ensemble system capable of applying TI analysis to multiple
 subsets and combining the results of these analyses.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Intro motivation and decision-making
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Formal Setting
\end_layout

\begin_layout Standard
We use the notation of Vapnik - given three components:
\end_layout

\begin_layout Enumerate
A generator (G) of random vectors 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

, drawn independantly from a fixed but unknown probability distribution
 function 
\begin_inset Formula $F(x)$
\end_inset


\end_layout

\begin_layout Enumerate
A supervisor (S) who returns an output value 
\begin_inset Formula $y$
\end_inset

 to every input vector 
\begin_inset Formula $x$
\end_inset

, according to a conditional distribution function 
\begin_inset Formula $F(y|x)$
\end_inset

, also fixed but unknown
\end_layout

\begin_layout Enumerate
A learning machine (LM) capable of implementing a set of functions 
\begin_inset Formula $\varphi(x,\alpha),\ \alpha\in\Lambda$
\end_inset

, where 
\begin_inset Formula $\Lambda$
\end_inset

 is a set of parameters
\end_layout

\begin_layout Standard
Our goal is to choose the function which best approximates the supervisor's
 response, given a set of observations:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =x_{1},...,x_{\ell}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We choose between potential functions based on the empirical risk function
 using the loss (discrepancy) 
\begin_inset Formula $L(y,f(x,\alpha))$
\end_inset

 between the response 
\begin_inset Formula $y$
\end_inset

 for a given value of 
\begin_inset Formula $x$
\end_inset

 and the predicted value 
\begin_inset Formula $f(x,\alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
R_{\text{emp}}(\alpha) & =\frac{1}{\ell}\sum_{i=1}^{\ell}L(y_{i},f(x_{i},\alpha))\\
 & =\frac{1}{\ell}\sum_{i=1}^{\ell}Q(z_{i},\alpha)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We define our problem as one of estimating a Probability Density Functions
 (PDF), so we define the set of observations as a random variable of arbitrary
 dimensions:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =(\Omega,\mathcal{F},\mathcal{P})\\
\Omega & \in\mathbb{R}^{d}\\
X & =[\vec{x}_{1},...,\vec{x}_{\ell}]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Our objective is to develop an estimate 
\begin_inset Formula $\varphi(x:\ X)$
\end_inset

 of the probability of the given point 
\begin_inset Formula $x$
\end_inset

 given a set of observations 
\begin_inset Formula $X$
\end_inset

 assuming some minimal uncertainty 
\begin_inset Formula $\xi$
\end_inset

 in the data:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X) & \longmapsto\Pr(x|X)\pm\xi\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Organize as follows: 1)Introduction and formal setting 2) Distance measure
 3) Parzen Estimator and SV Estimator 4) TI Entropy measure 5) Ensemble
 System 6) Motivated Decision Making
\end_layout

\end_inset


\end_layout

\begin_layout Section
Transformation Invariant Parzen Windows
\end_layout

\begin_layout Subsection
Parzen Windows for i.i.d.
 Data
\end_layout

\begin_layout Standard
Our task is to estimate the probability of a given vector 
\begin_inset Formula $\vec{x}$
\end_inset

 in the abstract space 
\begin_inset Formula $\Omega$
\end_inset

 based on a set of observations 
\begin_inset Formula $X$
\end_inset

.
 One method of accomplishing this is by using the Parzen Window (PW) method.
 We choose the Parzen Window method because it allows us to estimate probabiliti
es of unordered sets, provided they have an addition operation and a kernel
 function exists to provide a distance metric.
 The basic operation of the PW method is to estimate the probability of
 a point based on the sum of the distance from that point to each point
 in a set of prior observations.
 The Parzen Window approach to probability density function (PDF) estimation
 is as follows; given a set of prior observations 
\begin_inset Formula $X$
\end_inset

 and a kernel function 
\begin_inset Formula $K_{\gamma}(\cdot,\cdot)$
\end_inset

 with width parameter 
\begin_inset Formula $\gamma$
\end_inset

, the probability of a point 
\begin_inset Formula $\vec{x}$
\end_inset

 is determined by :
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & =\sum_{i}^{\ell}\frac{1}{\ell}K_{\gamma}(\vec{x},\vec{x}_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Multiple kernel functions exist, in this paper we will use the Radial Basis
 Function (RBF) kernel:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
K_{\gamma}\left(\vec{x},\vec{y}\right) & =\prod_{\upsilon=1}^{d}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{\nu},y^{\nu}\|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 is some metric, for instance the 
\begin_inset Formula $L^{2}$
\end_inset

 distance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|x,y\| & =\left(x-y\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This approach is useful in the context of a set of observations drawn i.i.d.
 from a static PDF, however it is unable to address transformation invariance.
 Transformation invariance (TI) refers to datasets in which one or multiple
 PDF's occur in various transformed states within the dataset, for example
 a given sound (described by a known PDF) could be repeated multiple times
 in an audio recording, or a given image could appear in multiple locations
 in a larger image.
 While the PW method can generate an estimate in the presence of data generated
 by transformed PDF's, its inability to recognize multiple instances of
 a single PDF limits its rate of convergence.
 
\end_layout

\begin_layout Subsection
Contextual Estimation
\end_layout

\begin_layout Standard
The crucial distinction between i.i.d data from a static PDF and data which
 exhibits TI is that when estimating the probability of a point, you must
 consider to context of the point as well as the location of the point in
 
\begin_inset Formula $\Omega$
\end_inset

.
 In this paper we will establish the context of 
\begin_inset Formula $x$
\end_inset

 by defining a 'neighborhood' of points around 
\begin_inset Formula $x$
\end_inset

 which we will refer to as a window 
\begin_inset Formula $w$
\end_inset

 on 
\begin_inset Formula $X$
\end_inset

.
 Because a TI analysis may be applicable to some dimensions of 
\begin_inset Formula $\Omega$
\end_inset

 and not other, we will define the set of dimensions for which TI analysis
 is used as 
\begin_inset Formula $D$
\end_inset

, the the set of dimensions 
\emph on
not 
\emph default
used for TI analysis as 
\begin_inset Formula $\tilde{D}$
\end_inset

, and the set of all dimensions of 
\begin_inset Formula $\Omega$
\end_inset

 as 
\begin_inset Formula $D^{X}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
D^{X} & =[0,...,d]\\
D & \subseteq D^{X}\\
\tilde{D} & =[n\in D^{X}|\ n\notin D]\\
\vec{x}_{i} & \longmapsto w_{i}^{D}\\
w_{i}^{D} & =[x_{i}^{n}|\ n\in D]\\
w_{i}^{n} & =x_{i}^{n}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
While the window 
\begin_inset Formula $w$
\end_inset

 describes the 
\emph on
location 
\emph default
of a window, we still must define its extents.
 We will do so through the use of a windowing kernel function 
\begin_inset Formula $\omega(\cdot)$
\end_inset

 parameterized by some variable 
\begin_inset Formula $\alpha$
\end_inset

 which returns a value describing the degree of inclusion of an arbitrary
 point and 
\begin_inset Formula $x$
\end_inset

 in the window 
\begin_inset Formula $w$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\omega_{\alpha}(w,x) & \Rightarrow[0,\infty)\\
\int_{-\infty}^{\infty}\omega_{\alpha}(w,x)dx_{i} & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can use any kernel function for 
\begin_inset Formula $\omega(\cdot)$
\end_inset

, however we assume that the windowing function has a peak at 
\begin_inset Formula $w_{i}=[x_{j}^{n}|\ n\in D]$
\end_inset

 and that it drops off as 
\begin_inset Formula $\left\Vert w_{i}-[x_{j}^{n}|\ n\in D]\right\Vert \rightarrow\pm\infty$
\end_inset

.
 Notice that we use a real-valued rather than boolean inclusion metric -
 this allows us to 'smear' the context of a given window into adjacent areas
 of 
\begin_inset Formula $X^{D}$
\end_inset

.
\end_layout

\begin_layout Subsection
Parzen Windows for Transformation-Invariant Data
\end_layout

\begin_layout Standard
Because we must establish a context for TI data, we must think of the set
 of observations 
\begin_inset Formula $X$
\end_inset

 as part of both the problem definition and the solution.
 This means that we can no longer simply calculate the kernel distance between
 
\begin_inset Formula $x$
\end_inset

 and each of the observations in 
\begin_inset Formula $X$
\end_inset

 independantly - we must compare the 
\emph on
context
\emph default
 of 
\begin_inset Formula $x$
\end_inset

 with contexts of 
\begin_inset Formula $X$
\end_inset

.
 This requires a kernel function capable of comparing two 
\emph on
sets of points
\emph default
.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
K_{\gamma}\left(X_{i},X_{j}\right) & =\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|X_{i},X_{j}\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can simplify this equation by observing that we are not actually dealing
 with two sets; we're dealing with two windows 
\begin_inset Formula $w_{n}$
\end_inset

 and 
\begin_inset Formula $w_{m}$
\end_inset

 within 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
K_{\gamma}\left(w_{n},w_{m},X\right) & =\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n},w_{n},X\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can extend this basic result to multiple dimensions by using the tensor
 product of the kernel values.
 In this context we must distinguish between TI dimensions and non-TI dimensions
, as the distance metric will be different for e
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
ach
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
K_{\gamma}\left(w_{n}^{D},w_{m}^{D},X\right) & =\prod_{\nu\in\tilde{D}}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\left(x_{n}^{\nu}-x_{m}^{\nu}\right)^{2}}\prod_{\nu\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{D},w_{n}^{D},\nu,X\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
There are multiple divergence measures available which can be used to define
 a 'distance' between two sets.
 We will later show the importance of the distance metric 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 being integrable; for this reason we will use the Pearson Divergence as
 our distance metric when comparing sets.
 In order to acommodate linear transformations, we add a 
\begin_inset Formula $d\times d$
\end_inset

 transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 and a 
\begin_inset Formula $d\times1$
\end_inset

 shift matrix 
\begin_inset Formula $\mathbf{b}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X^{\nu},Y^{\nu}\| & =\sum_{x^{\nu}\in\{X\cup Y\}}\left(\frac{\varphi(x^{\nu}:\ \mathbf{A}^{\nu}X^{\nu}+\mathbf{b}_{\nu})}{\varphi(x^{\nu}:\ Y^{\nu})}-1\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because the Pearson Divergence is a summation, we can control the influence
 of each point by scaling it using the windowing function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{D},w_{m}^{D},\nu,X\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{D},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{D},X)}-1\right)^{2}\\
\varphi(x^{\nu}:\ w_{n}^{D},X) & =\sum_{i=1}^{\ell}\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}K_{\gamma}(x^{\nu},x_{i}^{\nu})\\
 & =\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ K_{\gamma}(x^{\nu},x_{i}^{\nu})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
These two matrix transformations are used to shift, scale, rotate, shear
 or mirror the window 
\begin_inset Formula $w_{n}^{D}$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

.
 The first transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 is an 
\begin_inset Formula $d\times d$
\end_inset

 matrix.
 The linear operator 
\begin_inset Formula $\mathbf{A}X$
\end_inset

 allows us to scale, rotate, shear, and mirror 
\begin_inset Formula $X$
\end_inset

 depending on the matrix values of 
\begin_inset Formula $\mathbf{A}$
\end_inset

.
 The second transformation amtrix 
\begin_inset Formula $\mathbf{b}$
\end_inset

 is a 
\begin_inset Formula $d\times1$
\end_inset

 matrix; adding these terms together allows us to shift 
\begin_inset Formula $X$
\end_inset

 along any axis based on the values of 
\begin_inset Formula $\mathbf{b}$
\end_inset

.
 
\end_layout

\begin_layout Standard
One approach to these transformations is to explicitly determine values
 for the two matrices and to determine the distance 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 using these values.
 A more robust approach is to integrate over all possible values of 
\begin_inset Formula $(\mathbf{A},\mathbf{b}):$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{D},w_{m}^{D},\nu,X\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This approach allows us to compare the distance between 
\emph on
any
\emph default
 linear transformation 
\begin_inset Formula $\mathbf{A}X+\mathbf{b}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, a far more powerful and less computationally demanding approach.
 Doing so requires that we calculate the following integral:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\]

\end_inset


\end_layout

\begin_layout Standard
Because 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

 is a pair of matrix transformation, we must integrate the previous equation
 element-wise:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\end{align*}

\end_inset


\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}_{\nu,0},...,d\mathbf{A}_{\nu,d}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Explain all this shit below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
f([x^{0},...,x^{d}]:\ a,b,c,f,h) & =\left(a\ \exp\left(-b\left(\left(x^{d}\right)^{2}+x^{d}\sum_{i=1}^{d-1}x^{i}c^{i}+f\right)\right)-h\right)^{2}\\
\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d} & =\int...\int f\left([x^{0},...,x^{d-1}]:\ \frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}},-\frac{b}{2},-2bf,0\right)\ dx^{0},...,dx^{d-1}\\
 & \qquad\qquad+\int f\left([x^{0},...,x^{d-1}]:\ \frac{-2a\sqrt{\pi}}{\sqrt{b}},-\frac{b}{4},-4f,0\right)\ dx^{0},...,dx^{d-1}\\
\int f([x^{0}]:\ a,b,f,h)\ dx^{0} & =\frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}}\exp\left(-\frac{1}{2}b^{2}f\right)-\frac{2a\sqrt{\pi}}{\sqrt{b}}\exp\left(-bf\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x^{\nu}:\ w_{n}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int\left(\frac{\varphi\left(x^{\nu}:\ w_{n}^{\nu},\left[\mathbf{b}_{\nu}+\sum_{n=1}^{|D|}\mathbf{A}_{\nu,n}x_{i}^{n}|\ x_{i}\in X\right]\right)}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b}\\
 & =\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d}d\mathbf{b}_{\nu}\\
a & =\frac{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)}{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ \exp\left(-\frac{1}{\gamma}\left(x^{\nu}-x_{i}^{\nu}\right)^{2}\right)}\\
b & =\frac{1}{\gamma}\\
c & =???\\
f & =\left(x^{\nu}\right)^{2}-2x^{\nu}\mathbf{b}_{\nu}+\mathbf{b}_{\nu}^{2}\\
h & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make a note that for d not in D, A_dd=0, b=0
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Performance
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Big-O
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Multiple Data Sources
\end_layout

\begin_layout Standard
Consider the case where data from multiple data sources contributes to our
 set of observations 
\begin_inset Formula $X$
\end_inset

, for instance the data drawn from a microphone and a video camera.
 Let us assume that both input sources are timestamped, but the sampling
 frequency is different for each source and that the vector data points
 have different dimensionality.
 We will refer to observations of the former as 
\begin_inset Formula $X=(\Omega^{X},\mathcal{F}^{X},\mathcal{P}^{X})$
\end_inset

 and the latter as 
\begin_inset Formula $Y=(\Omega^{Y},\mathcal{P}^{Y},\mathcal{F}^{Y})$
\end_inset

.
 In this situation we can treat the timestamp as a 'shared' dimension, but
 all other dimensions of the two vectors are independant.
 It is clear that if we intend to establish a PDF of the joint probability
 space 
\begin_inset Formula $(\Omega^{Y,X},\mathcal{P}^{Y,X},\mathcal{F}^{Y,X})$
\end_inset

, we must treat each dimension in 
\begin_inset Formula $\Omega^{X}$
\end_inset

 and 
\begin_inset Formula $\Omega^{Y}$
\end_inset

 as orthonormal to each other.
 The fact that both event spaces share a time dimension means that a TI
 analysis over the two time dimensions is likely to produce useful results.
 
\end_layout

\begin_layout Standard
The most straightforward way to handle this situation is to assume that
 vector observations constitute sparse matrices; for any given dimension
 of an observation 
\begin_inset Formula $\vec{x}$
\end_inset

, the value can either be a real number or null:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
x^{\nu} & \in[\mathbb{R},\textrm{Ã˜}]\end{align*}

\end_inset

 In this case we only include operations between real-valued dimensions
 in our analysis.
 We can easily accomodate the shared time dimension by including the two
 time dimensions in our TI analysis.
 This allows us to consider not only the situation where both inputs are
 timestamped with accurate clocks, but the situation where the two clocks
 are independantly inaccurate and some transformation is required for them
 to show the same time.
\end_layout

\begin_layout Subsection
Single Channel Summary
\end_layout

\begin_layout Standard
We have developed a PDF estimation technique which allows us to take advantage
 of TI data.
 The solution uses a novel distance metric to compare the similarity between
 two sets of points in the context of arbitrary linear transformations of
 one set.
 The solution proposed is restricted to observations with shared dimensionality,
 however it imposes no restrictions on which dimensions are TI.
 The types of transformations considered by the proposed solution are restricted
 to linear matrix transformations shifts.
 In the next section we will extend the solution to cases where multiple
 'channels' of data are present allowing us to handle TI between observations
 with non-shared dimensions.
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}\ K_{\gamma}(w^{D},w_{i}^{D},\{\vec{x}\cup X\})\\
K_{\gamma}\left(w_{n}^{D},w_{m}^{D},X\right) & =\prod_{\nu\in\tilde{D}}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\left(x_{n}^{\nu}-x_{m}^{\nu}\right)^{2}}\prod_{\nu\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{D},w_{n}^{D},\nu,X\|}\\
\|w_{n}^{D},w_{m}^{D},\nu,X\| & =???\\
\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X) & =\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}\end{align*}

\end_inset


\end_layout

\begin_layout Section
Support Vector Optimizations
\end_layout

\begin_layout Standard
The Parzen Window method is neither sparse nor computationally efficient,
 and as the number of observations grows, these deficiencies quickly become
 prohibitive.
 We now investigate the use of Support Vector Machines to generate estimates.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Refer to big-O
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Generalized Parzen-SVM 
\end_layout

\begin_layout Standard
Support Vector Machines (SVM) are often used
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
ref?
\end_layout

\end_inset

 to estimate probability distributions by solving the related problem of
 estimating the cumulative distribution function of the random variable
 in question.
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
This isn't really the essence of SVM - put more verbage in the intro regarding
 what SVM's are, why they work, and why they're superior to other approaches
 (say, neural networks)
\end_layout

\end_inset

 This reduces the problem to one of estimating a non-linear mapping from
 observations to cumulative distribution values, which can be formulated
 as an optimization problem over a linear operator equation.
 Unfortunately, these methods depend on the ability to calculate an empirical
 distribution for each observation:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
F_{\ell}(x)=\frac{1}{\ell}\sum_{i}\theta(x-x_{i})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\theta(x)$
\end_inset

 is the indicator function.
 To evaluate this function, the abstract space 
\begin_inset Formula $\Omega$
\end_inset

 must be ordered.
 While we have described a distance metric over 
\begin_inset Formula $\Omega$
\end_inset

, it is not clear what a meaningful ordering relation would be.
\end_layout

\begin_layout Standard
Rather than calculating the cumulative probability distribution of 
\begin_inset Formula $X$
\end_inset

, we begin with the assumption that the PW estimate of the probability distribut
ion is acceptably accurate and attempt to minimize the difference between
 the Support Vector (SV) estimate and the PW estimate.
 In this spirit, we will use a modification of the PW estimator which substitute
s a set of weights 
\begin_inset Formula $\beta$
\end_inset

 for the normalizing contant 
\begin_inset Formula $\frac{1}{\ell}$
\end_inset

 in the PW equation:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ \beta,X) & =\sum_{i=1}^{\ell}\beta_{i}K_{\gamma}(w^{D},w_{i}^{D},X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The support vector approach requires that we define an optimization problem
 
\begin_inset Formula $W(\beta)$
\end_inset

 to determine the value of 
\begin_inset Formula $\beta$
\end_inset

.
 This optimization problem will determine which observations (or as we shall
 see, windows) will be used in estimations and which can be discarded as
 redundant or irrelevant information.
 The result of the optimization problem will be that a substantial number
 of multipliers 
\begin_inset Formula $\beta_{i}$
\end_inset

 will be 
\begin_inset Formula $0$
\end_inset

, allowing us to omit the windows defined by these points in the prediction
 phase.
 We define the optimization problem as minimizing the square loss between
 the SV and PW estimates over some set of observations 
\begin_inset Formula $X$
\end_inset

.
 The set of weights used in the Support Vector estimation must have a discrete
 number of elements; for simplicity we choose to assign a weight to each
 window defined by the time value of an observation in the training set
 and the constant parameter 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)-\varphi(\vec{x}_{i}:\ \beta,X)\right)^{2}+\beta\Omega(\lambda,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss regularizier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the optimization problem, we check the difference between the two estimates
 at windows defined by the observations 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss the equations below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)-\varphi(\vec{x}_{i}:\ \beta,X)\right)^{2} & =\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)\right)^{2}-2\left(\varphi(\vec{x}_{i}:\ X)\varphi(\vec{x}_{i}:\ \beta,X)\right)+\left(\varphi(\vec{x}_{i}:\ \beta,X)\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
 & =\sum_{i=1}^{\ell}\left(\sum_{j=1}^{\ell}\frac{1}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)^{2}-2\left(\sum_{j=1}^{\ell}\frac{1}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)\left(\sum_{j=1}^{\ell}\beta_{j}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)\\
 & \qquad\qquad\qquad+\left(\sum_{j=1}^{\ell}\beta_{j}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)^{2}\\
 & =\sum_{i=1}^{\ell}\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell^{2}}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{k}^{D},X)-2\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\beta_{j}K_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & \qquad\qquad\qquad+\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\beta_{j}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & =\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\beta_{k}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{k}^{D},X)-\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{2\beta_{j}}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{jk}^{D},X)\\
 & \qquad\qquad\qquad+\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell^{2}}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{k}^{D},X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because this is a minimization problem we can eliminate the last term (changing
 
\begin_inset Formula $\beta$
\end_inset

 won't affect its value).
 Substituting our optimization problem becomes:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\beta_{k}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & \qquad\qquad\qquad-\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{2\beta_{j}}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)K_{\gamma}(w_{i}^{D},w_{k}^{D},X)+\lambda\Omega(\beta,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\text{subject to} & \beta_{i}\ge0,\ \sum\beta=1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Shouldn't the second term only have one kernel function? If not combine
 the first two terms
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Quadratic Optimization Problem
\end_layout

\begin_layout Subsection
Support Vector Decomposition 
\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout
This section is probably better as an appendix
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Due to the simplicity of the constraints in the optimization problem, it
 is possible to use the decomposition method of Osuna to reduce the memory
 requirements of the Parzen-SVM algorithm.
\end_layout

\begin_layout Subsubsection
 Sub-Problem Definition 
\end_layout

\begin_layout Standard
The decomposition algorithm breaks 
\begin_inset Formula $X$
\end_inset

 into two working sets 
\begin_inset Formula $B,N$
\end_inset

, and attempts to optimize 
\begin_inset Formula $B$
\end_inset

 while keeping 
\begin_inset Formula $N$
\end_inset

 fixed.
 This results in the following iterative optimization problem where 
\begin_inset Formula $\boldsymbol{\beta}^{k}$
\end_inset

 denotes the result of the previous iteration:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\boldsymbol{\beta}_{B}) & =\frac{1}{2}\begin{bmatrix}\boldsymbol{\beta}_{B}^{T} & (\boldsymbol{\beta}_{N}^{k})^{T}\end{bmatrix}\begin{bmatrix}P_{BB} & P_{BN}\\
P_{NB} & P_{NN}\end{bmatrix}\begin{bmatrix}\boldsymbol{\beta}_{B}\\
\boldsymbol{\beta}_{N}^{k}\end{bmatrix}-\begin{bmatrix}q_{B}^{T} & q_{N}^{T}\end{bmatrix}\begin{bmatrix}\boldsymbol{\beta}_{B}\\
\boldsymbol{\beta}_{N}^{k}\end{bmatrix}\\
 & =\frac{1}{2}\boldsymbol{\beta}_{B}^{T}P_{BB}\boldsymbol{\beta}_{B}-(-q_{B}+P_{BN}\boldsymbol{\beta}_{N}^{k})^{T}\boldsymbol{\beta}_{B}\\
 & =\frac{1}{2}\begin{bmatrix}\beta_{i} & \beta_{j}\end{bmatrix}\begin{bmatrix}P_{ii} & P_{ij}\\
P_{ij} & P_{jj}\end{bmatrix}\begin{bmatrix}\beta_{i}\\
\beta_{j}\end{bmatrix}-(-q_{B}+P_{BN}\boldsymbol{\beta}_{N}^{k})^{T}\begin{bmatrix}\beta_{i}\\
\beta_{j}\end{bmatrix}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\text{subject to}\quad0\le\beta_{i},\beta_{j},\quad\beta_{i}+\beta_{j}=1-\mathbf{1}^{T}\boldsymbol{\beta}_{N}^{k}\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
 Working Set Selection 
\end_layout

\begin_layout Standard
Select
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
 & i\in\text{arg}\max_{t}\left\{ -\nabla f(\boldsymbol{\beta}^{k})_{t}\ |\quad t\in I(\boldsymbol{\beta}^{k})\right\} \\
 & j\in\text{arg}\min_{t}\left\{ -\frac{b_{it}^{2}}{a_{it}}\ |\quad t\in I(\boldsymbol{\beta}^{k}),\quad-\nabla f(\boldsymbol{\beta}^{k})_{t}<-\nabla f(\boldsymbol{\beta}^{k})_{i}\right\} \end{align}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% This needs to be checked for the new optimization scenario
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
I(\boldsymbol{\beta}) & \equiv\{t\ |\quad\beta_{t}<1\quad\text{or}\quad\beta_{t}>0\}\\
 & a_{it}=P_{ii}+P_{tt}-2P_{it}\\
 & \bar{a}_{it}=\begin{cases}
a_{it} & \text{if}\ a_{it}>0\\
\delta & \text{otherwise}\end{cases}\\
 & b_{it}=-\nabla f(\boldsymbol{\beta}^{k})_{i}+\nabla f(\boldsymbol{\beta}^{k})_{t}\\
\nabla f(\boldsymbol{\beta})_{i} & \equiv P_{i}\boldsymbol{\beta}-q_{i}\end{align}

\end_inset


\end_layout

\begin_layout Subsubsection
 Stopping Condition 
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\max_{i\in I(\boldsymbol{\alpha}^{k})}-\nabla f(\boldsymbol{\alpha})_{i}+\min_{j\in I(\boldsymbol{\alpha}^{k})}\nabla f(\boldsymbol{\alpha})_{j}\le\epsilon\end{equation}

\end_inset


\end_layout

\begin_layout Section
Ensemble System
\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout
This section is likely to change drastically
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We now discuss creating a system composed of multiple estimators.
 It is well known that using a combination of estimates drawn from different
 models of an underlying phenomenon tends to increase the prediction accuracy
 of the hybrid system.
 We will begin by establishing an explanation for this phenomenon based
 on the concepts of VC Entropy and the uniform bounds on convergence of
 learning processes.
 We will then develop a method of qantifying the rate of convergence of
 an individual estimator, and show how this quantification can be used to
 build an optimal ensemble system of estimators.
 The basic question we will address is 
\emph on
how does one choose sets of dimension which will benefit from TI analysis,
 and how do we control the computational demands of an ensemble system?
\end_layout

\begin_layout Subsection
VC Entropy and Bounds on the Rate of Convergence
\end_layout

\begin_layout Standard
We begin by describing the VC entropy of a set of estimators using their
 risk values 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 defined by the set of parameters 
\begin_inset Formula $\alpha$
\end_inset

.
 Given a set of observations 
\begin_inset Formula $X=[x_{1},...,x_{\ell}]$
\end_inset

, we can construction a set of 
\begin_inset Formula $\ell$
\end_inset

-dimensional vectors
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
q(\alpha) & =[Q(x_{1},\alpha),...,Q(x_{\ell},\alpha)]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Each vector describes the loss of a given element of 
\begin_inset Formula $\alpha$
\end_inset

 for the observations 
\begin_inset Formula $X$
\end_inset

.
 We define the minimum number of vectors required to 'cover' 
\begin_inset Formula $q(\alpha)$
\end_inset

 with some arbitrarily small measure of closeness 
\begin_inset Formula $\varepsilon$
\end_inset

 as 
\begin_inset Formula $N^{\Lambda}(\varepsilon:x_{1},...,x_{\ell})$
\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
For example, if 
\begin_inset Formula $q(\alpha)=[1,2,4,1]$
\end_inset

, 
\begin_inset Formula $N^{\Lambda}(X)=3$
\end_inset


\end_layout

\end_inset

.
 Using this value, we caluclate the VC Entropy 
\begin_inset Formula $H^{\Lambda}(X)$
\end_inset

 of the set of functions 
\begin_inset Formula $Q(x,\alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H^{\Lambda}(\varepsilon:\ell) & =\ln N^{\Lambda}(\varepsilon:x_{1},...,x_{\ell})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The VC Entropy essentially describes the number of observations in 
\begin_inset Formula $X$
\end_inset

 required to describe the PDF 
\begin_inset Formula $\mathcal{P}$
\end_inset

, based on the assumption that if multiple points in 
\begin_inset Formula $X$
\end_inset

 are 
\begin_inset Formula $\varepsilon$
\end_inset

-close to each other, we can eliminate all but one in our estimator.
 The VC Entropy is distribution-specific; it depends on the specific set
 of vectors 
\begin_inset Formula $q(\alpha)$
\end_inset

.
 In order to generate distribution-independant bounds, we establish the
 growth function 
\begin_inset Formula $G^{\Lambda}(\ell)$
\end_inset

 which describes the maximal value of 
\begin_inset Formula $H^{\Lambda}(\ell)$
\end_inset

 for any distribution given the set of estimators defined by 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
G^{\Lambda}(\ell) & =\ln\sup_{x_{1},...,x_{\ell}}N^{\Lambda}(x_{1},...,x_{\ell})\\
H^{\Lambda}(\ell) & \le G^{\Lambda}(\ell)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It can be shown that the following equations hold true with probability
 
\begin_inset Formula $(1-\eta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Psi & =4\frac{G^{\Lambda}\left(2\ell\right)-\ln\left(\eta/4\right)}{\ell}\\
R(\alpha) & \le R_{\text{emp}}(\alpha)+\frac{\Psi}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}(\alpha)}{\Psi}}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This equation describes the upper bound on the risk of estimators from the
 set 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 for 
\begin_inset Formula $\ell$
\end_inset

 observations, when the empirical risk is equal to 
\begin_inset Formula $R_{\text{emp }}(\alpha)$
\end_inset

.
 It can be further shown that the growth function is bounded by
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
G^{\Lambda} & \le h\left(\ln\frac{\ell}{h}+1\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $h$
\end_inset

 describes the VC Dimension of the estimator, defined as the maximum number
 of vectors that can be linearly separated by the estimator (in the case
 of binary estimators) or as the VC Dimension of the set of indicators 
\begin_inset Formula $I(x,\alpha,\beta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
I(x,\alpha,\beta) & =\theta(Q(x:\ \alpha)-\beta),\ \alpha\in\Lambda,\ \beta\in(0,1)\\
\theta(x) & =\begin{cases}
0 & \quad\text{if}\ x<0,\\
1 & \quad\text{if}\ x\ge0\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In other words the VC Dimension of a real-valued estimator is determined
 by the miximum number of vectors which can be enclosed by a region with
 radius 
\begin_inset Formula $1-\beta$
\end_inset

.
 In practical terms, this means that the VC Dimension is defined by the
 granularity of the estimator 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

.
 Recall that PDF's are bounded by 
\begin_inset Formula $(0,1)$
\end_inset

; this means that each dimension of any loss vector 
\begin_inset Formula $q(\alpha_{n})$
\end_inset

 must be between 
\begin_inset Formula $(0,1)$
\end_inset

.
 Therefore the VC Dimension of an estimator is determined by the maximum
 number of regions with radius 
\begin_inset Formula $1-\beta$
\end_inset

 which can be defined on the interval 
\begin_inset Formula $(0,1)$
\end_inset

 in 
\begin_inset Formula $\ell$
\end_inset

 dimensions.
 In the case of SVM estimators, the value 
\begin_inset Formula $h$
\end_inset

 can be determined after optimizing for 
\begin_inset Formula $\beta$
\end_inset

 as the ratio of Support Vectors to 
\begin_inset Formula $\ell$
\end_inset

.
\end_layout

\begin_layout Subsection
Bounds of Convergence for TI Analysis
\end_layout

\begin_layout Standard
The growth function is used to characterize the worst-case performance for
 a specific type of estimator; we now show that the worst-case performance
 of an estimator capable of TI analysis is upper bounded by the growth function.
 Consider the PDF generated by a given estimator 
\begin_inset Formula $\varphi(x:\ \alpha_{n})$
\end_inset

 and two loss functions; the loss function 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 defined by the distance between 
\begin_inset Formula $\varphi(x:\ \alpha_{n})$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, and the loss function 
\begin_inset Formula $Q_{TI}(x:\ \alpha)$
\end_inset

 defined by the TI distance between the same.
 It can easily be shown that 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 is a special case of 
\begin_inset Formula $Q_{TI}(x:\ \alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
Q(x:\ \alpha) & =Q_{TI}(x:\ \alpha),\quad\mathbf{A}=I,\ \mathbf{b}=0\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Recall that TI estimators are generated from the integral of the distance
 between two sets under transformations.
 We can therefore construct the following inequality:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X,Y\| & \ge\int\|X,\mathbf{A}Y+\mathbf{b}\|d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is clear therefore that the TI loss will be less than or equal to the
 distance loss, and that the growth function for a given closeness parameter
 will be less for the TI estimator than the distance estimator.
 
\end_layout

\begin_layout Subsection
Bayesian Model Averaging Ensemble Machine
\end_layout

\begin_layout Standard
We now develop a method of combining multiple estimators into a single learning
 machine.
 Our discussion of TI analysis has assumed that the distance metric is integrate
d over some set of dimensions 
\begin_inset Formula $D$
\end_inset

.
 In the case of high-dimensional datasets the computational demands of integrati
ng over set set of all dimensions in 
\begin_inset Formula $X$
\end_inset

 may outweigh the utility of doing so.
 We instead consider using multiple partitions of 
\begin_inset Formula $\bar{D}$
\end_inset

 to generate partial estimators.
 We can further extend the flexibility of the ensemble system by restricting
 each partial estimator to a subset of observations 
\begin_inset Formula $X^{D}\subseteq X$
\end_inset

.
 We therefore define a set of partial estimators:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi^{n}(x:\ X^{n},D^{n}) & \longmapsto\Pr(x|X^{n})\approx\Pr(x|X)\\
X^{n} & \subseteq X\\
D^{n} & \subseteq\bar{D}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
With associated risk bounds
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In the case of Parzen Estimators we can set the empirical risk to 0, in
 the case of SVM estimators we can set the empirical risk to the minimal
 value of the optimization problem.
\end_layout

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Psi^{n} & =4\frac{G^{\Lambda}\left(2|X^{n}|\right)-\ln\left(\eta/4\right)}{|X^{n}|}\\
R^{n}(\alpha) & \le R_{\text{emp}}^{n}(\alpha)+\frac{\Psi}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}^{n}(\alpha)}{\Psi}}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Consider the case of multiple partial estimators which makes estimates of
 
\begin_inset Formula $\Pr(x|X)$
\end_inset

 which we would like to combine.
 Consider the two resulting extimates of the probability of a given point
 
\begin_inset Formula $x$
\end_inset

.
 Using Bayesian Model Averaging (BMA) we can average the estimators weighted
 by their respective confidence interval
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Technically, they are being weighted by the probability that each estimator
 is accurate given 
\begin_inset Formula $X$
\end_inset

.
 Given a confidence interval, the relative probability that each estimate
 is accurate is determined by the confidence interval of the estimators.
 In this context, the concepts of risk and confidence interval are interchangabl
e.
\end_layout

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
If that footnote is correct, it's odd that we need to normalize this.
 And if we don't need to normalize it, how do we account for a thousand
 estimators with decent confidence interval being combined?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & \approx\sum_{n}\Pr(x|\varphi^{n},X)\Pr(\varphi^{n}|X)\\
 & \approx\frac{1}{\sum_{n}1-R^{n}(\alpha)}\sum_{n}\varphi^{n}(x:\ X^{n},D^{n})(1-R^{n}(\alpha))\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Merging Estimators with Shared Dimensional Sets
\end_layout

\begin_layout Standard
This result allows us to create hybrid estimates based on a set of estimators
 regardless of the dimensional sets used by the estimators or the subsets
 of 
\begin_inset Formula $X$
\end_inset

 used by the estimators.
 We now consider a similar situation; combining the estimates of estimators
 based on the same dimensional set.
 In this context it is possible to to generate an estimator using the union
 of the observations from the two original estimators.
 This approach has a significant benefit over the BMA approach described
 above; it allows the hybrid estimator to generate estimates using the joint
 entropy of the observations, rather than the posterior probability of the
 marginal entropy of the two estimators.
 If we describe the entropy of two estimators as 
\begin_inset Formula $H(X^{1})$
\end_inset

 and 
\begin_inset Formula $H(X^{2})$
\end_inset

, the entropy of the union of these two subsets is lower bounded by the
 sum of the marginal entropies:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H(X^{1}\cap X^{2}) & \ge H(X^{1})+H(X^{2})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Unfortunately we cannot simply combine the two subsets 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

; doing so would violate the i.i.d.
 requirement of the PW estimator.
 To demonstrate this, consider a situation in which both subsets are drawn
 randomly from 
\begin_inset Formula $X$
\end_inset

 within some bounds 
\begin_inset Formula $(a^{1},b^{1})$
\end_inset

 and 
\begin_inset Formula $(a^{2},b^{2})$
\end_inset

 defined along some dimension of 
\begin_inset Formula $X$
\end_inset

 (ie we draw 
\begin_inset Formula $n$
\end_inset

 observations from 
\begin_inset Formula $X$
\end_inset

 from a specific time window).
 Within the context of each estimator the i.i.d.
 constraints are met within the defined bounds, however combining these
 two sets will only produce i.i.d.
 data if 
\begin_inset Formula $a^{1}=a^{2},\ b^{1}=b^{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Consider the requirement of i.i.d.
 data in PW estimators; the probability of a given point is determined by
 the sum of the kernel distance to each observation used by the estimator.
 More observations in a given region increases the probability estimate
 for any point near that region.
 Let us assume that the bounds of one estimator are contained in and smaller
 than the bounds of a second:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
a^{1} & <a^{2}\\
b^{1} & >b^{2}\\
|X^{1}| & =|X^{2}|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, a PW estimator would incorrectly generate elevated probability
 estimates in the region 
\begin_inset Formula $(a^{2},b^{2})$
\end_inset

 and lowered estimates in the compliment.
 We have already seen how SVM estimators achieve performance optimization
 by adjusting the weight 
\begin_inset Formula $\beta$
\end_inset

 given to each observation; we now propose a similar weighting mechanism
 
\begin_inset Formula $\rho(n)$
\end_inset

 which adjusts the influence of each point in the union of the two sets
 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

 so that the estimates of a PW estimator based on the union of two i.i.d.
 data sets remain accurate estimates of the underlying PDF.
 We now show that the weighting mechanism must be based on the risk of the
 two estimators; given two estimators 
\begin_inset Formula $\varphi^{n}(x:\ X^{n},D^{i})$
\end_inset

 and 
\begin_inset Formula $\varphi^{m}(x:\ X^{m},D^{i})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X,D) & =\sum_{i=1}^{\ell}\frac{1}{\ell}K_{\gamma}(x,x_{i})\\
\varphi^{n,m}(x:\ X^{n}\cap X^{m}:D^{i}) & =\frac{\varphi^{n}(x:\ X^{n},D^{i})(1-R^{n}(\alpha))+\varphi^{n}(x:\ X^{n},D^{i})(1-R^{m}(\alpha))}{2-R^{n}(\alpha)-R^{m}(\alpha)}\\
 & =\frac{(1-R^{n}(\alpha))}{2-R^{n}(\alpha)-R^{m}(\alpha)}\sum_{x_{i}\in X^{n}}\frac{1}{|X^{n}|}K_{\gamma}(x,x_{i})+\frac{(1-R^{m}(\alpha))}{2-R^{n}(\alpha)-R^{m}(\alpha)}\sum_{x_{i}\in X^{m}}\frac{1}{|X^{m}|}K_{\gamma}(x,x_{i})\\
 & =\sum_{x_{i}\in X^{n}\cup X^{m}}\rho(x_{i}:\ \varphi^{n},\varphi^{m})\frac{1}{|X^{n}|+|X^{m}|}K_{\gamma}(x,x_{i})\\
\rho(x:\ \varphi^{n},\varphi^{m}) & =\begin{cases}
\frac{(1-R^{n}(\alpha))}{|X^{n}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)} & \quad x\in X^{n},x\notin X^{m}\\
\frac{(1-R^{m}(\alpha))}{|X^{m}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)} & \quad x\notin X^{n},x\in X^{m}\\
\frac{(1-R^{n}(\alpha))}{|X^{n}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)}+\frac{(1-R^{m}(\alpha))}{|X^{m}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)} & \quad x\in X^{n},x\in X^{m}\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This can be extended to SVM estimators:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi^{n,m}(x:\ \beta,X) & =\sum_{x_{i}\in X^{n}\cup X^{m}}\beta_{i}\rho(x:\ \varphi^{n},\varphi^{m})K_{\gamma}(x,x_{i})\\
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{\begin{array}{c}
x_{i}\in X^{n}\cup X^{m}\\
x_{j}\in X^{n}\cup X^{m}\\
x_{k}\in X^{n}\cup X^{m}\end{array}}\beta_{j}\beta_{k}\rho(x_{j}:\ \varphi^{n},\varphi^{m})\rho(x_{k}:\ \varphi^{n},\varphi^{m})K_{\gamma}(x_{i},x_{j})K_{\gamma}(x_{i},x_{k})\\
 & \qquad\qquad\qquad-\sum_{\begin{array}{c}
x_{i}\in X^{n}\cup X^{m}\\
x_{j}\in X^{n}\cup X^{m}\end{array}}\frac{2\beta_{j}}{\ell}\rho(x_{j}:\ \varphi^{n},\varphi^{m})K_{\gamma}(x_{i},x_{j})+\lambda\Omega(\beta,X^{n}\cup X^{m})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
I don't think the second term is correct - work this through the equations.
 Also make sure the second term only needs one kernel term (note in SV section)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that both sets being combined must be i.i.d.; this means that single observati
ons in isolation cannot be added.
 The minimum number of points in a set required for the set to constitue
 i.i.d.
 data is determined by the number of dimensions in the dimensional set.
 The risk value 
\begin_inset Formula $R(\alpha)$
\end_inset

 is also a worst-case scenario, rather than an exact measure; the more points
 in a given subset.
 This can be accomodated by combining sets with sufficient observations
 that the contribution of the empirical risk is greater than the contribution
 of the growth function.
 In general terms, the more observations in the combined sets, the more
 accurate the weighting term 
\begin_inset Formula $\rho(\cdot)$
\end_inset

 will be.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Show a second iteration of this process
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Computational Considerations in Subset Selection
\end_layout

\begin_layout Standard
In general, computational demands will vary with different classes of estimators.
 TI estimators have far higher computational cost than point-based estimators.
 We assume that there exist more classes of estimators than are necessary
 to produce a given risk for a given set of observation, which leaves us
 with the task of selecting which estimators to apply to an estimation problem
 and how to assign observations to the selected estimators.
 To make these decisions, we develop a selection heuristic based on the
 costs and benefits of using a given estimator.
\end_layout

\begin_layout Standard
The basic approach we will describe is an iterative one; we first select
 an i.i.d.
 subset 
\begin_inset Formula $X'$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

, then add the subset to one or more estimators from the set of possible
 estimators based on some heuristic.
 At each iteration we update our selection heuristic based on the results
 of the previous addition of 
\begin_inset Formula $X'$
\end_inset

.
 This approach allows us to control both the set of estimators used and
 the observations assigned to each estimator; more importantly it allows
 us to do so based on the nature of the observations 
\begin_inset Formula $X$
\end_inset

.
 We will show that it is possible to build a heuristic which requires no
 additional computation, allowing us to simultaneously build estimators
 and optimize subsequent iterations.
\end_layout

\begin_layout Standard
The simplist portion of the heuristic to define is the cost of using an
 estimator.
 The computational complexity of estimators can generally be determined
 
\emph on
a priori
\emph default
 as a function of the number and dimensionality of the estimator.
 In some cases optimizations exist which are data-dependant; in these cases
 we will assume a worst-case scenario for additional observations.
 We define the cost function for a given estimator as 
\begin_inset Formula $c(n,X)$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 denotes the number of observations which will be added and 
\begin_inset Formula $X$
\end_inset

 denotes the observations used by the estimator.
\end_layout

\begin_layout Standard
The benefit portion of the heuristic can be easily constructed from previous
 work.
 For any estimator, the utility of the estimator is described by the risk
 associated with the estimator.
 In generating estiamtes our primary goal is to produce accurate estimates,
 and the risk function 
\begin_inset Formula $R(\alpha)$
\end_inset

 describes the lowest possible accuracy of a given estimator.
 It is clear therefore that the utility of adding observations to an estimator
 is determined by the change in the expected risk as a result of adding
 observations; estimators which we expect to gain a high reduction in risk
 should be preferred over estimators which we expect to gain a small reduction
 in risk.
 Recall that the maximal risk is determined by the number of observations
 used by the estimator, the empirical risk of the estimator, and the estimator's
 growth function; all three of these values are known for a given estimator
 withou additional computation
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The empirical risk for an SVM estimator is the minimal value of the optimization
 problem.
 The empirical risk of a Parzen Estimator can be assumed to be 0.
\end_layout

\end_inset

.
 We can therefore define the benefit function for a given estimator as 
\begin_inset Formula $b(n,X)$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 denotes the number of observations which will be added and 
\begin_inset Formula $X$
\end_inset

 denotes the observations used by the estimator:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
b(n,X) & =R(\alpha)-R(\alpha_{n})\\
R(\alpha_{n}) & =R_{\text{emp}}(\alpha)+n+\frac{\Psi_{n}}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}(\alpha)+4n}{\Psi_{n}}}\right)\\
\Psi_{n} & =4\frac{G^{\Lambda}\left(2\left(|X|+n\right)\right)-\ln\left(\eta/4\right)}{|X|+n}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can now define our heuristic 
\begin_inset Formula $h(n,X)$
\end_inset

 as the difference of the benefit and the cost, scaled by some parameter
 
\begin_inset Formula $\lambda$
\end_inset

 which controls the trade-off between accuracy and performance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
h(n,X) & =b(n,X)-\lambda c(n,X)\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Hierarchical Ensemble Estimators
\end_layout

\begin_layout Standard
The ensemble system presented above is formulated in the context of traditional
 point-based probability estimators (as opposed to set-based TI estimators).
 The equations also hold in the context of combining estimates from point-based
 and set-based estimators.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Conclusions:
\end_layout

\begin_layout Itemize
x We can combine multiple LM's by averaging them weighted by their level
 of risk
\end_layout

\begin_layout Itemize
x We can combine multiple observations from different LM's into a single
 LM (provided they have the same dimensional set) by adding a multiplier
 to each observation based on the level of risk of the LM from which they
 were derived.
 If observations exist in both LM's being combined, they are weighted by
 the sum of the risk levels in the two LM's
\end_layout

\begin_layout Itemize
x We can add single points to an LM, but we must include the new point's
 nearest neighbors in the risk multiplier (and update the multipliers of
 the neighbors).
\end_layout

\begin_layout Itemize
x Since adding a point to an LM requires computation, we can choose between
 dimensional sets based on the expected risk decreas and the computational
 cost of adding a point to that dimensional set.
 Larger decreases in risk are better, and lower computational cost is better.
 The influence of each can be adjusted using a single variable.
\end_layout

\begin_layout Itemize
x We can calculate the change in risk of a dimensional set using the empirical
 risk of any existing observations as a base and the bounds on the growth
 function to extrapolate some number of additional observations.
 
\end_layout

\begin_layout Itemize
In the same way that neighborhood probabilities can be projected onto point
 probabilities, probabilities on higher levels can be projected onto lower
 levels, using the same risk evaluation function
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\lyxline

\end_layout

\begin_layout Standard
Due to the computational demands of TI analysis a set of heuristics for
 choosing when to use TI analysis and when to use more traditional means
 is needed.
 In its most general form, our task is to select subsets of 
\begin_inset Formula $X$
\end_inset

 for which to integrate over transformations.
 Unfortunately this decision cannot be made 
\emph on
a priori,
\emph default
 it must be data-dependant.
 The objective therefore is to develop a means of estimating the efficacy
 of a TI analysis without going through the process of completing said analysis.
 
\end_layout

\begin_layout Standard
The TI entropy of a set of observations is determined by the minimum number
 of vector sets required to cover the observations to some measure of closeness.
 Determining this value requires that we first cosntruct a distance matrix
 between the observations and then use some algorithm to determine the number
 of points needed to cover the observations.
 We can construct an upper bound on the TI Entropy through simpler analyses
 of the distance matrix.
 The simplist is to determine the maximal number of points needed to cover
 a given set of observations by determining how many elements of the distance
 matrix are less than our closeness parameter
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Consider the case where all but to observations are not 'close'; there will
 be two elements in the distance matrix less than our closeness parameter.
 
\end_layout

\end_inset

.
 We can describe the maximal number of point needed to cover a given set
 of observations as the square root of the number of elements in the distance
 matrix less than our closeness parameter:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
D_{i} & =[\|x_{i},x_{n}\|\ |\ \|x_{i},x_{n}\|<\varepsilon]\\
H_{\max}^{\Lambda}(\ell) & =\ell-\sum_{i=1}^{\ell}|D_{i}|-i\\
H^{\Lambda}(\ell) & \le H_{\max}^{\Lambda}(\ell)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can further refine this by using the kernel distance between observations:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{K}^{\Lambda}(\ell) & =\ell-\sum_{i=1}^{\ell}\sum_{j=i}^{\ell}K_{\gamma}(x_{i},x_{j})\\
H^{\Lambda}(\ell) & \le H_{K}^{\Lambda}(\ell)\le H_{\max}^{\Lambda}(\ell)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
The loss function used above is specific to a set of dimensions which are
 being compared - the next step is to compare different sets of dimensions
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Regarding optimization...
\end_layout

\begin_layout Plain Layout
once the distance matrix for a set of observations has been calculated,
 there isn't necessarily a large increse in the cost of minimizing for weights
 (and no cost in the case of Parzen) aside from the potential increase in
 the size of the kernel matrix.
 This is due to the fact that the kernel matrix is determined as the product
 of each dimension, possibly with additional terms if a given dimension
 is included in multiple TI sets.
 In essence; determining the distance matrix is *the* optimization problem.
\end_layout

\begin_layout Plain Layout
Minimizing the computational cost of a given dimensional set distance matrix
 can only be reduced by reducing the number of observations used for the
 distance matrix.
 This means that we have two choices; which observations to include in a
 comparison set and which dimensional sets to check.
 The former needs to retain the i.i.d.
 nature of the observations, so should probably be a random sampling (although
 this is an interesting area of manipulation if, for instance, you want
 to weight the system towards recent observations).
 In the case of the latter we have two options; randomly choose dimensional
 sets, or develop some heuristic enabling us to pick sets based on some
 already-known information about the data - the only such heuristic I can
 think of would be based on the observations about the relative entropy
 of a set and partitions of that set.
\end_layout

\begin_layout Plain Layout
Picking sets of dimensions will need (as discussed) a cost function for
 computing the distance matrix of *any* set (of the given dimension), an
 understanding of the relationship between the entropy of different sets,
 and knowledge of existing dimensional sets (to be used with the previous
 understanding).
 One thing we can know for sure is that if the choice parameter is absolute
 (rather than relative, ie.
 take the top 5 sets) if it's worthwhile to calculate a given dimensional
 set, it's not worthwhile to calculate any paritions of that set (since
 the information of the set includes any information contained in the partitions
).
 We also know that since entropy is additive, the minimum entropy of the
 union of two disjoint sets will be the sum of the entropy of the two sets;
 if this minimum satisfies the choice parameter, we can substitute the union
 for the two subsets.
 We should develop an understanding of the union of non-disjoint sets as
 well.
\end_layout

\begin_layout Plain Layout
Let's establish the basic search algorithm:
\end_layout

\begin_layout Enumerate
evaluate the 0-d entropy of the set (this is essentially the VC Entropy
 calculated for pairs of observations with no context) and use to initialize
 the predicted entropy of all partitions of d
\end_layout

\begin_layout Enumerate
pick the dimensional set with the highest predicted entropy (if multiple
 sets share the maximal value pick among them at random)
\end_layout

\begin_layout Enumerate
evaluate the entropy of the picked set over a subset of observations
\end_layout

\begin_layout Enumerate
update predicted entropy based on the observed set
\end_layout

\begin_layout Enumerate
if evaluated entropy meets demands expand calculation, else return to 2
\end_layout

\begin_layout Enumerate
if computational resources allow, return to 2
\end_layout

\begin_layout Plain Layout
One thing that's not clear is the relationship between our search and the
 actual estimation process.
 It would be nice if the two were integrated; *any* distance matrices generated
 in the search were used in estimation.
 In this case, we could also treat our heuristic as part of an integrated
 system; the number of observations in a dimensional set could be gradually
 increased or decreased based on the observed entropy.
 Can this be accomplished easily in the structure as it exists?
\end_layout

\begin_layout Plain Layout
Let's try to develop this.
 In this case, each dimensional set constitutes its own LM, and our task
 is simply to integrate the estimates of different LM's (this is needed
 in any case for the ensemble system).
 The nice thing is that we can caluclate the minimal accuracy of each LM
 (either related to the risk or the confidence interval).
 It should be possible to use this information in some way to combine them.
 This is a nice observation, because it allows us to handle different dimensiona
l sets as well as heirarchical information in a uniform manner (assuming
 we can translate accuracy of upper layers into accuracy of lower layers).
 Let's recall that the kernel distance for multi-dimenaional predictions
 is the product of the kernel distance over each dimension - it stands to
 reason that adding a multiplier based on accuracy would make sense; the
 traditional multiplier is in the context of dimensions which are assumed
 to carry equivalent information.
 Let's propose this:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi(x:\ X) & =\sum_{i=1}^{\ell}\prod_{D\in\mathbf{D}}\mathcal{K}_{\gamma}(x,x_{i}:\ D)\\
\mathcal{K}_{\gamma}(x,x_{i}:\ D) & =\begin{cases}
\rho(D,X^{D})\beta_{i}^{D}K_{\gamma}(x,x_{i}:\ D) & \quad x_{i}\in X^{D}\\
1 & \quad\text{otherwise}\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
This leaves us (again) with the task of selecting which dimensional set
 to add observations to, complicated now by the fact that each dimensional
 set will have a different number of observations.
 We need a method of comparing the entropy of sets with different numbers
 of observations.
 I think the best solution to this is to observe that the growth function
 (and thus the observed entropy, I think) is upper bounded by a known function.
 This allows us to normalize each estimate to ell - essentially taking the
 observed entropy and projecting it to the worst case scenario and then
 comparing these worst-case scenarios.
 If this can be justified, it provides a seamless way to compare the expected
 entropy of two sets with different numbers of observations.
 As the number of observations in one grows, the expected entropy in the
 worst case converges on the actual, so if the entropy of the more-defined
 set is greater than the worst-case scenario of the less-defined set, we
 know that we should work on the less defined set.
 In essence, we simply pick the estimate that has the lowest worst-case
 estimate given the observations.
 This approach can be easily adjusted to take computational demands into
 account, in fact if we assume we're going to add one observation at a time,
 we can determine the exact computational demands based *both* on the dimensiona
lity *and* the number of observations.
 This would tend to promote dimensional sets with few observations over
 those with many, even if the expected entropy of the former is greater
 than the latter (in some cases), which is probably good; we strike the
 optimal balance between performance and accuracy using a simple parameter
 which scales the influence of the computational demands.
 This is in additition to the benefit of the fact that we can choose to
 add observations only when resources are available.
\end_layout

\begin_layout Plain Layout
Let's return briefly the the issue of choosing an observation to add.
 The previous stuff simply determines when to add an observation and to
 which LM; it doesn't make any demands on which point is chosen.
 The question is if i.i.d.
 data requires random selection, or if we can tweak the selection process
 (ie select more recent points).
 In a Parzen estimator, I don't think we could tweak the selection process
 - the probability is determined by the number of points in a given vicinity,
 so selecting for specific values would skew this estimate.
 It may be possible to adjust for this using the SVM approach, since the
 weight of each point's influence is controlled for each observation, and
 it should be possible to correct for any selection bias; in this case we
 would simply be increasing the prediction accuracy for points near where
 our sampling bias occurred.
 I'm not sure how doing this would influence the optimization problem; increasin
g the accuracy implies increasing the nubmer of SV's, so we would inevitably
 get more SV's in the region being selected for.
 It would seem that the weight adjustment would need to be applied after
 the optimization problem was completed.
 I'm also not sure how to modify that weight - we would probably need to
 choose at random based on a distribution, then weight points based on the
 distribution.
 If we're talking about an online system, the selection distribution would
 be tricky.
 We could determine the distribution is observations were equally spaced
 in time, the sampline rate was constant, and the selection was random,
 but in the context of optimized sampline I'm not sure what the distribution
 would be.
 Maybe we use a sampling distribution which was uniform across scales (exponent,
 inverse?) - this would mean that whenever we made a sampling the probability
 distribution would remain the same.
 Unfortunately, I don't see how we could simply add the most recent observation
 to some subset of LM's and be able to generate useful data (the sampling
 distribution would be based on the computational resources and the entropy
 of each partition at each point in time).
 One nice thing about being able to do this is that it would allow us to
 discard data at some point.
 If we were sampling randomly, we would have to retain all the data in the
 system in order to sample from it - even if the data wasn't being used
 in predictions, it would *all* have to be retained in order for the system
 to increase its prediction accuracy.
 Reducing the probability of including a point would allow us to discard
 non-SV data once its selection probability dropped below some threshold.
 OK - so we need to develop a system for doing this.
 It should be as simple as establishing a selection distribution and a weight
 function to correct it.
\end_layout

\begin_layout Plain Layout
Handling non-iid data needs attention.
 Even though the time dimension is part of the estimates, the time dimension
 is assumed to correlate with different behaviors in other dimensions, thus
 we cannot properly estimate the probability of the other dimensions unless
 the time dimension is iid.
 Let's assume we have a set of observations X taken before some time value,
 and for which we have already determined SV's using a random sampling from
 X.
 We now need to add a set of observations Y, taken after the time; we need
 to add observations from Y to the LM in such a way that iid data is retained.
 If the observations of X are iid, mean of the distance between observations
 will approach the duration of X divided by the number of points sampled.
 To add Y to X, we must retain this mean.
 This means that we can add at most one observation from Y for each segment
 of the mean contained in the duration of Y, or alternately if we are going
 to simply add a single point it must be chosen at random from the first
 mean-window of Y.
 This isn't really a great solution, as if we repeated this process indefinately
, the result would be less random than if we selected the maximum number
 of points from Y possible.
 
\end_layout

\begin_layout Plain Layout
Perhaps we can simply assume that each time a sample is drawn, it is drawn
 from the set of observations which have occurred since the last sample
 was drawn (in this case we assume multiple samples are drawn at each sampling).
 This allows us to establish the sampling rate for each period between samplings
; so long as each sampling is randome we should be able to weight the results
 based on the sampling rate (the multiplier would be the inverse of the
 sampling rate, or duration/samples).
 This could even be extended to single samples; each sample would be weighted
 by the duration since the last sample.
 This system would both allow us to front-load samples and to go back and
 fill in previous periods afterwards (which would be nice because it allows
 shallow on-line awareness as well as a more exhaustive off-line investigation).
\end_layout

\begin_layout Plain Layout
I think this (stratified) method might work - what we need to establish
 now is how it integrates into the optimization procedure.
 In this case, we don't want weights to be affected by the sample rate,
 so the sample rate will need to show up in the optimization process somewhere.
 I think we can just add the weight term before the multipliers in both
 parzen and SVM estimates and end up with the proper result.
\end_layout

\begin_layout Plain Layout
Consider a dataset with a single observation is surrounded by no observations
 and a cluster of observations with highly divergent associated values.
 In this case, the single observation will be weighted much higher than
 the cluster, however the cluster implies that the dataset has a lot of
 variation within small time windows.
 In this case, the result of the cluster should probably be more influential
 than the result of the point.
 Contrast this to a similar case where the cluster shows highly consistent
 associated values; in this case we should probably weight the two associated
 patterns equally.
 In other words, we need to take variation into account when doing this.
 What this means is that we need to use the confidence interval to scale
 observations, and the confidence interval needs to take the sampling rate
 into account in some way; in the case where the cluster is highly convergent.
 In the first case, the confidence interval for the cluster will be lower
 than in the latter case.
 We want to influcence of the cluster to be greater when the confidence
 interval for the cluster is high than when its low (high confidence interval
 means random process, in which case the point isn't much more releavnt
 than the cluster, lower confidence interval means well-behaved process
 in which both the point and the cluster can be treated as single observations).
 This means that the influence of a point needs to be scaled linearly with
 the confidence interval and inversely with the sampling rate.
 In other words, the less information a point contains, the lower its influence
 should be, or the less risk associated with an estimate derived from a
 given sampling, the more the sample rate should predominate.
\end_layout

\begin_layout Plain Layout
let's thinka about it this way; we're given a set of samples of X, each
 of the same duration.
 We want to combine them.
 It seems like it would makes sense to weight them based on the information
 contained in each sample.
 This would reduce to the earlier situation (the information in the convergent
 set is the same as the information contained in the point, and the information
 in the divergent sample is much more than the information contained in
 the point).
 The question is if it's possible to prove this makes sense.
 Intuitively, the iid case assumes that each observation carries an equal
 amount of information about the distribution, so they're all weighted equally
 - if a given set of observations holds more information about the distribution
 it should carry more weight than a set of observations which carry less
 information.
 This would require that we prove that our information measure is derived
 directly from the probability distribution.
\end_layout

\begin_layout Plain Layout
This approach requires that we extend it to arbitrarily sized samples, which
 probably means we need to define the information in a single point.
 In the uniform case, we're determining the information contained in the
 entire set, then applying that uniformly to each observation in that set;
 moving to a point-based information measure will require that we also take
 into account other points.
 At the same time, applying the information in a whole set to each point
 in the set seems less than idea; some points in that set may carry more
 information than others.
 Can we determine the information of a single point? Would we want to? If
 we simply calulated the information of each point relative the the distribution
 of all other points and then used this to weight points, what would the
 result be? outlyers would be weighted higher than 'normal' points - would
 this affect the final probability measure? Surely it would (in the Parzen
 sense), because any weighting of iid points would distort the probability
 measure.
 So we can't simply calculate the entropy of points.
 This implies that something must counteract the entropy of a given point
 - what would that be?
\end_layout

\begin_layout Plain Layout
Lets think in terms of subsets of X, and try to work out some method by
 which the PDF of the subsets approaches the PDF of X.
 The main difference here is that the entropy of a subset cannot be assumed
 to be the entropy of the full set.
 We can, however, state that the entropy of a subset is upper-bounded by
 the growth function plus the entropy of the observations.
 So maybe instead of considering the entropy of a set we consider the growth
 entropy of a set normalized to some number of observations (say the number
 of total observations)?
\end_layout

\begin_layout Plain Layout
This leads to the idea that we're dealing with multiple LM's, each defined
 by the set of observations in its sample subset.
 In this case, there's not really any reason to distinguish between LM's
 defined over different dimensional sets and LM's defined over different
 subsets of X; both express partial information about the distribution of
 X, and both need to be adjusted based on the expected risk of the estimator.
 This probably works great so long as each estimator has multiple observations,
 what do we do if each contains a single observation; it make it impossible
 to calculate SV's.
 maybe we can get out of this by first considering LM's as parzen estimators,
 then combining weighted estimators, then generalizing to SVM's.
\end_layout

\begin_layout Plain Layout
If we can justify combining multiple LM's using different dimensional subsets,
 we should be able to justify combining LM's using different observation
 sets.
 Once that has been formalized, it should be possible to construct a weighted
 Parzen estimator, then generalize it to a weighted SVM.
 We just need to formalize the justification for combining LM's.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
This allows us to combine observations with a weighting multiplier which
 factors out the lack of iid.
 This can be done recursively so that we repeatedly add observations without
 screwing up the estimator (in this case, the multipliers would be multiplied
 - this can all be shown as expansions of the Parzen estimator equation).
\end_layout

\begin_layout Plain Layout
The final question is how this operates in the context of TI.
 We can treat neighborhoods as points, but is there a problem comparing
 the neighborhoods to points? If we're adding all the points in a neighborhood,
 how do we distribute the weight of the neighborhood? The ideal solution
 would be to prove that we can extract the neighborhood weighting function
 from the kernel and apply it to the iid weighting function as a multiplier.
 One good thing is that there's no point in combining observations for different
 dimensional subsets; we'll always be comparing points within a subset.
 This means that we need to keep in mind that we're not combinging points,
 we're combining neighborhoods.
 This should allow us to ignore the issue completely; neighborhoods act
 as points, and they can be combined with a single multiplier.
 What you're starting to get at is an analysis of when a point can be discarded;
 we want to only discard points which aren't used in any SV's, which brings
 us back to the inclusion threshold.
 This isn't complicated.
\end_layout

\begin_layout Plain Layout
Given these observations, we can now even add single points; we use the
 risk associated with a single observation as the points risk.
 
\end_layout

\begin_layout Plain Layout
Here's an odd observation; if we're using the risk as the multiplier, as
 the risk increases the influence increases - this would seem to be the
 opposite of what we want? I think the probability should probably be 1-risk.
 This means that adding a single point will give it a multiplier very close
 to 0 - how does this work out as we add more and more points? The most
 recent points will have the highest multipliers, since the risk will necessaril
y be less than one, and over successive additions the older points will
 be diminished.
 This points to a problem with the recursive issue - perhaps it needs to
 be additive? In fact I think it must be - we can frame the issue as associative
 addition; X+Y+Z = (X+Y)+Z.
 In this case, the first two subsets are combined, then added to the third.
 This of course leads us to the opposite situation, where older observations
 have higher priority than newer.
 No, because the weights will only increase if we have the same point in
 multiple subsets.
 What this doesn't take into account is the fact that the combined observations
 have lower risk than the new ones - can we integrate this risk with the
 original risk? IE X+Y->X', X'+Z.
 I think we would have to treat X' as new subset of observations and scale
 each point based on that.
 To do this, we have to optimize with the weights from X,Y then replace
 these weights with a single weight from new calculation.
 But this won't work because we loose the iid fix - we'll certainly need
 to adjust the weights.
 It may be that allowing the weights to drift down is OK? No, I think the
 problem is that we must keep the individual iid weights.
 We can determine the risk of X', but it doesn't affect the constituent
 points; they are being weighted relative to each other given their weight
 when they were observed.
 Even then, the problem is that if we add each point with the minimal weight,
 they all end up with the same weight, which means we're back with the problem
 of no iid scaling.
 The problem (again) is that the risk value doesn't seem to care about the
 sampling rate.
\end_layout

\begin_layout Plain Layout
How about this, instead of adding one point at a time, we always add two
 points; the most recent point and the one before it.
 This means the entropy of both points is determined by the separation between
 them.
 It also means that points take into account their neighbors on both sides.
 I think this solves our main problem; it allows us to add one point at
 a time (by calculating the entropy of the point and the most recent one)
 and it allows us to respond to the sampling rate.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In comparing the relative value of adding some observations, we must estimate
 the reduction in risk adding these values will produce.
 A simple method of doing this is to assume that the new observations will
 have a negligable influence on the risk (as would be the case if you're
 adding a fraction of the total number of observations).
 This allows us to assume that the emprican risk and the VC Entropy will
 both remain constant, and we can simply check (for each LM's entropy and
 empirical risk) how adding observations will affect the maximal risk.
\end_layout

\begin_layout Plain Layout
This might be an area in which we can integrate surprisal - we somehow integrate
 the difference between the expected change in empirical risk to the actual
 (alternately we weight the calculation towards 'recent' observations).
 Maybe we establish a surprisal value which expresses the difference between
 the actual change in empirical risk (or VC Dimension) and expected.
 We could use a simple regression fit of these values to estimate future
 values (this would probably only work if we were comparing actual to steady-sta
te).
 Another approach would be to use the worst-case scenario, in which the
 loss was maximal for all new observations and each new observation became
 a SV (this is essentially tracking the growth function).
 It might be better to use this as the baseline.
\end_layout

\begin_layout Plain Layout
One last (I hope) question; how do we evaluate the expected change when
 l=0? In this case we need to evaluate what the risk of making an estimate
 from no observations is.
 In this the growth function isn't a problem (it's 0), and the confidence
 level isn't a problem.
 The equation, however, uses l in denominators, making it indeterminate.
 Let's thinking more generally about the risk.
 We're dealing with a worst-case scenario, and since we have nothing to
 generate our estimates, we have to assume that the worst case scenario
 is that our estimator has the maximal loss for each prediction.
 Unfortunately, we're bounded by (0,1), so the risk in this case is purely
 determined by the distribution.
 Let's take the worst case scenario then and assume that it's always the
 same value, and that our estimator always produces another value - our
 risk will be 1.
 In other words, we assume in the worst case scenario that our risk is the
 upper bound.
 In this case, the difference is 1-whatever.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
(Old) Contextual Information
\end_layout

\begin_layout Standard
Transformation invariance assumes that the context of an observation carries
 information relevant to the PDF of 
\begin_inset Formula $X$
\end_inset

 within that context.
 As such, we can say that the higher the expected information carried by
 a context, the more useful a TI analysis will be.
 This raises the question of how we determine the amount of information
 a given context contains 
\emph on
about the PDF within that context
\emph default
.
 In order for a context to contain information about itself, it must be
 similar to other contexts - we must have examples of similar behaviors
 from which we can generalize.
 So on the one hand, the more information we can extract from different
 contexts, the more likely we are to benefit from a TI analysis.
 On the other hand, if there are a relatively small number of divergent
 contexts, we can assume that the PDF of 
\begin_inset Formula $X$
\end_inset

 is not strongly contextualized, and therefore a TI analysis (based on contextua
l information) won't be particularly beneficial.
 These are the two factors which influence the relevance of a TI analysis;
 the variety of contexts and the overlap between contexts.
 In order to evaluate the relevance of TI analysis, we must develop orthogonal
 descriptions of these two factors.
 
\end_layout

\begin_layout Standard
The variety of contexts within a dataset can be described as the expected
 divergence between 
\emph on
adjacent
\emph default
 contexts:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\varepsilon}^{V}(X) & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\omega_{\varepsilon}(x_{i},x_{j})\omega_{\alpha}(x_{i},x_{j})\|x_{i},x_{j},X\|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The overlap between contexts can be described as the expected divergence
 between 
\emph on
all
\emph default
 contexts.
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\varepsilon}^{O}(X) & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\omega_{\alpha}(x_{i},x_{j})\|x_{i},x_{j},X\|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We would like the TI value to increase as either of these factors increase.
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\varepsilon}(X) & =H_{\varepsilon}^{V}(X)+H_{\varepsilon}^{O}(X)\\
 & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\omega_{\varepsilon}(x_{i},x_{j})\omega_{\alpha}(x_{i},x_{j})\|x_{i},x_{j},X\|+\frac{1}{\ell^{2}}\omega_{\alpha}(x_{i},x_{j})\|x_{i},x_{j},X\|\\
 & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\omega_{\alpha}(x_{i},x_{j})\|x_{i},x_{j},X\|\left(\omega_{\varepsilon}(x_{i},x_{j})+1\right)\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
(Old) Multi-dimensional Contextual Information
\end_layout

\begin_layout Standard
This can be extended to multi-dimensional data by observing that the window
 used previously is defined along a single dimension; we can just as easily
 consider a multi-dimensional window.
 In this case, we simply need to compare the expected divergence between
 adjacent windows in multiple dimensions and the expected divergence between
 all possible windows in multiple dimensions (here we use the 
\begin_inset Formula $L_{2}$
\end_inset

 metric):
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\varepsilon}^{V}(X) & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\sqrt{\sum_{\nu=1}^{d}\left(\frac{1}{\ell^{2}}\omega_{\varepsilon}(x_{i}^{\nu},x_{j}^{\nu})\omega_{\alpha}(x_{i}^{\nu},x_{j}^{\nu})\|x_{i}^{\nu},x_{j}^{\nu},X\|\right)^{2}}\\
H_{\varepsilon}^{O}(X) & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\sqrt{\sum_{\nu=1}^{d}\left(\frac{1}{\ell^{2}}\omega_{\alpha}(x_{i}^{\nu},x_{j}^{\nu})\|x_{i}^{\nu},x_{j}^{\nu},X\|\right)^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can refine these to apply only to a subset of 
\begin_inset Formula $d$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\varepsilon}^{V}(X:\ D) & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\sqrt{\sum_{\nu\in D}\left(\frac{1}{\ell^{2}}\omega_{\varepsilon}(x_{i}^{\nu},x_{j}^{\nu})\omega_{\alpha}(x_{i}^{\nu},x_{j}^{\nu})\|x_{i}^{\nu},x_{j}^{\nu},X,D\|\right)^{2}}\\
H_{\varepsilon}^{O}(X:\ D) & =\sum_{\begin{array}{c}
i=1\\
j=1\end{array}}^{\ell}\sqrt{\sum_{\nu\in D}\left(\frac{1}{\ell^{2}}\omega_{\alpha}(x_{i}^{\nu},x_{j}^{\nu})\|x_{i}^{\nu},x_{j}^{\nu},X,D\|\right)^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
(Old) Selecting TI Dimensions
\end_layout

\begin_layout Standard
We now turn our attention to the task of selecting which dimensions to include
 in 
\begin_inset Formula $D$
\end_inset

.
 The computational complexity of TI-analysis grows exponentially with 
\begin_inset Formula $|D|$
\end_inset

, therefore it is important that we only include dimensions which will increase
 the rate of convergence of 
\begin_inset Formula $\varphi(\vec{x}:\ X)$
\end_inset

 on 
\begin_inset Formula $\Pr(x|\ X)$
\end_inset

.
 To make things more challenging, the computational complexity of calculating
 
\begin_inset Formula $H_{\varepsilon}(X:\ D)$
\end_inset

 increases linearly 
\begin_inset Note Note
status open

\begin_layout Plain Layout
?
\end_layout

\end_inset

 with both 
\begin_inset Formula $|X|$
\end_inset

 and 
\begin_inset Formula $|D|$
\end_inset

, and the cardinality of the set of all possible subsets of 
\begin_inset Formula $D^{X}$
\end_inset

 is 
\begin_inset Formula $2^{|D^{X}|}$
\end_inset

 which quickly becomes intractable as 
\begin_inset Formula $|D^{X}|$
\end_inset

 increases.
 Our search algorithm therefore must take into account the cost and benefits
 of using a given set 
\begin_inset Formula $D$
\end_inset

 as well as the cost and benefits of determining 
\begin_inset Formula $H_{\varepsilon}(X:\ D)$
\end_inset

 for a given 
\begin_inset Formula $D$
\end_inset

.
\end_layout

\begin_layout Standard
Let us begin by considering information entropy in the abstract.
 Given a set of 2D vector observations 
\begin_inset Formula $X$
\end_inset

, we can state that the entropy of the vector set 
\begin_inset Formula $H(X)$
\end_inset

 is always great than or equal to the sum of the entropy of the two individually
:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H(X) & \ge H(X^{1})+H(X^{2})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This means that any set 
\begin_inset Formula $D'$
\end_inset

 which does not warrant TI analysis, no subset 
\begin_inset Formula $D"\subset D'$
\end_inset

 warrants analysis either:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\varepsilon}(X,D')<h & \longmapsto H_{\varepsilon}(X,D")<h,\quad\forall D"\subset D'\end{align*}

\end_inset


\end_layout

\begin_layout Standard
A second consideration relates to the number of observations used in the
 calculation of 
\begin_inset Formula $H(X)$
\end_inset

.
 Let us consider two disjoint subsets 
\begin_inset Formula $Y$
\end_inset

 and 
\begin_inset Formula $Z$
\end_inset

 of our full set of observations 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
Y & \subset X\\
Z & \subset X\\
Y\cap Z & =\emptyset\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Reviewing the equation for 
\begin_inset Formula $H(X)$
\end_inset

, it is clear that in the absence of the normalizer 
\begin_inset Formula $\frac{1}{|D|^{2}}$
\end_inset

, the sum of the contextual information for our two subsets would necessarily
 be less than both the contextual entropy of the union of these sets and
 the contextual information of 
\begin_inset Formula $X$
\end_inset

.
 We therefore establish a function which determines the minimum entropy
 of two such subsets:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H_{\min}(Y,Z:\ D) & =\frac{|Y|^{2}H_{\varepsilon}(Y:\ D)+|Z|^{2}H_{\varepsilon}(Z:\ D)}{\left(|Y|+|Z|\right)^{2}}\\
H_{\min}(Y,Z:\ D) & \le H_{\varepsilon}(Y\cup Z:\ D)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As discussed earlier, the utility of a given set 
\begin_inset Formula $D$
\end_inset

 can be expressed by the amount of contextual information encoded by 
\begin_inset Formula $D$
\end_inset

, for which we have established the metric 
\begin_inset Formula $H_{\varepsilon}(X:\ D)$
\end_inset

.
 We also know that the cost of using a given subset 
\begin_inset Formula $D$
\end_inset

 can be expressed as 
\begin_inset Formula $\mathcal{O}(2^{|D|})$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Cost function?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Algorithm needs to choose between partitioning a dimensional set and evaluating
 more data points for a data set.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Is this the system's dream state?
\end_layout

\end_inset


\end_layout

\begin_layout Section
Ensemble System
\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout
The ideas here are OK, but the notation needs a lot of work
\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are limits to the predictive ability of the current architecture.
 Most significantly, the context which influences a prediction is limited
 by the nature of 
\begin_inset Formula $\omega(\cdot,\cdot)$
\end_inset

.
 A more robust architecture would allow the context of a prediction to be
 more flexible, for example responding to two discrete windows while ignoring
 data outside those windows.
 A simple example of this is delayed causality; recognizing the relationship
 between an action and a delayed result requires that the system be capable
 of ignoring the intervening data.
 One solution to this limitation is to include multiple windows in the context
 of an estimate.
 In this case we would compare data drawn from multiple windows to data
 in a similar set of windows in 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Standard
Another perspective on this limitation is that the estimates we generate
 (as well as the contexts from which we make the estimates) is limited by
 the nature of 
\begin_inset Formula $\omega(\cdot,\cdot)$
\end_inset

; it would be helpful for our estimates to make predictions about the probabilit
y of values in multiple windows of the abstract space 
\begin_inset Formula $\Omega^{X}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Taken together, we can see that a superior architecture would be capable
 of making estimates in the form of multiple windows using on observations
 
\emph on
based
\emph default
 on multiple windows.
 This can be accomplished by treating the distance between sets of windows
 over 
\begin_inset Formula $X$
\end_inset

 as independant observations of the random variable 
\begin_inset Formula $Y$
\end_inset

.
 
\end_layout

\begin_layout Standard
We can refer to a window over 
\begin_inset Formula $X$
\end_inset

 defined in partition of dimensions 
\begin_inset Formula $D$
\end_inset

 as a vector 
\begin_inset Formula $w^{D}$
\end_inset

.
 For any such window defined by a point 
\begin_inset Formula $w_{n}^{D}$
\end_inset

, we define the value of the point 
\begin_inset Formula $y_{m}^{n}$
\end_inset

 in the abstract space 
\begin_inset Formula $\Omega^{Y}$
\end_inset

as the divergence between 
\begin_inset Formula $X$
\end_inset

 in the window 
\begin_inset Formula $w_{n}^{D}$
\end_inset

 the window 
\begin_inset Formula $w_{m}^{D}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
y_{m}^{n} & =g(w_{m}^{D}:\ X)\\
g(w_{m}^{D}:\ X) & =\|x_{n},x_{m},X,D\|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
FIX THE D NOTATION THROUGHOUT
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The dimensionality of 
\begin_inset Formula $\Omega^{Y}$
\end_inset

 is determined by the number of windows over 
\begin_inset Formula $X$
\end_inset

 which are used as observations of 
\begin_inset Formula $Y$
\end_inset

.
 We can define the value of each dimension of 
\begin_inset Formula $Y$
\end_inset

 at any point 
\begin_inset Formula $D_{i}$
\end_inset

 by determining the divergence between that dimension's corresponding window
 over 
\begin_inset Formula $X$
\end_inset

 and the window over 
\begin_inset Formula $X$
\end_inset

 defined by 
\begin_inset Formula $D_{i}$
\end_inset

.
 Because observations of 
\begin_inset Formula $Y$
\end_inset

 are derived from 
\begin_inset Formula $X$
\end_inset

, we must establish some method of choosing values of 
\begin_inset Formula $D$
\end_inset

 for which to derive observations; the nature of this method will depend
 on the nature of the data being analyzed and the computational resources
 available.
 We leave this for future investigation.
\end_layout

\begin_layout Standard
The generation of estimates of 
\begin_inset Formula $\mathcal{P}^{Y}$
\end_inset

 in a given window 
\begin_inset Formula $D$
\end_inset

 can be accomplished using the techniques already set forth, and in this
 sense the revised architecture is recursive.
 The estimator for each abstract space is referred to as a 'layer'; depending
 on the way estimates are used, the system can be seein as either a hierarchical
 system or a feed-forward system.
 We define a layer as such:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi^{i+1}(g(x:\ X^{i}):\ X^{i+1}) & \longmapsto\Pr(g(x:\ X^{i})|X^{i+1})\pm\xi\\
X^{i+1} & =[g(x_{1}:\ X^{i}),...,g(x_{\ell^{i+1}}:\ X^{i})]\\
g(x:\ X^{i}) & =\left[\|x_{1},x,X^{i},D\|,...,\|x_{d^{i+1}},x,X^{i},D\|\right]\\
g(x:\ X^{i+1})^{j+1} & =g(g(x:\ X^{i})^{j}:\ X^{i+1})\\
g(x:\ X^{i})^{0} & =\|x_{n},x_{m},X,D\|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We must therefore develop a method of translating estimates in the abstract
 space 
\begin_inset Formula $\Omega^{Y}$
\end_inset

 into estimates in the abstract space 
\begin_inset Formula $\Omega^{X}$
\end_inset

.
 One method is to use a feed-forward system, transforming a prediction 
\begin_inset Formula $y_{i}$
\end_inset

 into a PDF in 
\begin_inset Formula $\Omega^{X}$
\end_inset

.
 Because each dimension of 
\begin_inset Formula $y_{i}$
\end_inset

 is defined as a PDF in 
\begin_inset Formula $\Omega^{X}$
\end_inset

 and combining these PDF's is a trivial task.
 There are two weakness in this approach; it requries that the all the informati
on in a window 
\begin_inset Formula $D_{n}$
\end_inset

 over 
\begin_inset Formula $X$
\end_inset

 be used in generating values of 
\begin_inset Formula $y^{n}$
\end_inset

 and our predictions are limited by the sampling rate of 
\begin_inset Formula $Y$
\end_inset

.
 A more robust approach would allow the full use of the information contained
 in 
\begin_inset Formula $X$
\end_inset

 regardless of the amount of information transferred from 
\begin_inset Formula $X$
\end_inset

 to 
\begin_inset Formula $Y$
\end_inset

 (determined by the sampling rate and method of generating observations).
 A better approach is to use a hierarchical system in which we use some
 combination of predictions drawn from each layer of the architecture:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X^{1},...,X^{\mu}) & =f\left(\varphi^{1}(x:\ X^{1}),...,\varphi^{\mu}(g(x:\ X^{\mu-1})^{\mu-1}:\ X^{\mu}):\ \lambda\right)\\
\int_{-\infty}^{\infty}f(x)dx & =1\\
0\le f(x)\le1 & \forall x\end{align*}

\end_inset


\end_layout

\begin_layout Standard
One way of doing this would be to simply take the product of each estimate
 weighted by some parameter to control the influence of different layers:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X^{1},...,X^{\mu}) & =\prod_{n=1}^{\mu}\lambda^{n}\varphi^{n}(x:\ X^{n})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This system is not strictly hierarchical; we can determine the influence
 of each layer individually (potentially favoring lower layers over higher
 ones), however we refer to it as such because successive layers have an
 increased scope of data from which to make predictions, and each of these
 is eventually combined in making estimates.
 
\end_layout

\begin_layout Subsection
Example System Architecture
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Control the dimensionality of this by restricting scope to adjacent windows?
\end_layout

\begin_layout Plain Layout
if we do SV points, those points will need to have D as dimensions - they'll
 need to know the context on which a given SV pattern occurred.
\end_layout

\begin_layout Plain Layout
Treat the SV points as sparse datasets using a divergence threshold.
\end_layout

\begin_layout Plain Layout
Here's what I'm thinking.
 We start from the perspective of a single TI dimension.
 We generate estimates in the dimension alone and isolate some SV's.
 We then begin to compare that dimension to others to see if shared TI is
 worthwhile.
 Using the other dimensions which match, we construct a new estimator using
 data points based on the shared dimensions and sparse SV's from the two
 dimensions.
 We can then build up to a third layer by comparing the SV's from the second
 layer to SV's in other dimensions, again generating a set of shared TI
 dimensions.
\end_layout

\begin_layout Plain Layout
This needs refinement - we may run into the ambiguity of the channels again.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Motivated Decision-Making
\end_layout

\begin_layout Standard
Up to this point, our discussion has focused on data analysis.
 We now turn our attention to volitive systems; systems which have the ability
 influence the the probability distribution 
\begin_inset Formula $\mathcal{P}$
\end_inset

 of the observation space 
\begin_inset Formula $\Omega$
\end_inset

, and in which certain types of local probability distributions are preferred
 over others.
 
\end_layout

\begin_layout Subsection
Setting of the Motivation Problem
\end_layout

\begin_layout Standard
We assume that such a system influences 
\begin_inset Formula $\mathcal{P}$
\end_inset

 through actions which are discrete and quantifiable.
 Each action is therefore described as a vector 
\begin_inset Formula $\vec{a}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\vec{a}_{i} & =\left[a_{i}^{1},...,a_{i}^{\pi}\right]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In order to correlate actions with changes in 
\begin_inset Formula $\mathcal{P}$
\end_inset

, we treat each action as an observation of 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =(\Omega,\mathcal{F},\mathcal{P})\\
\Omega & \in\mathbb{R}^{d+\pi}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, our observations are of dimension 
\begin_inset Formula $d+\pi$
\end_inset

, the first 
\begin_inset Formula $d$
\end_inset

 dimensions describe the system's 'environment' and the last 
\begin_inset Formula $\pi$
\end_inset

 describe the system's 'actions'.
 In order to choose between possible actions, the system must prefer certain
 states of the input space 
\begin_inset Formula $\Omega$
\end_inset

 over others.
 We describe these preferred states as the system's using a function 
\begin_inset Formula $m_{\theta}(x:\ X)$
\end_inset

 we'll refer to as the motivator with control parameter 
\begin_inset Formula $\theta$
\end_inset

.
 The for a given dimension of 
\begin_inset Formula $\Omega$
\end_inset

, the motivator function returns a positive real value describing the system's
 preference for the state 
\begin_inset Formula $x^{i}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
m_{\theta}(x^{i}:\ X) & \in\mathbb{R}^{+}\\
m_{\theta}(x^{i}:\ X)>1 & \longmapsto\text{preferred state}\\
m_{\theta}(x^{i}:\ X)<1 & \longmapsto\text{discouraged state}\\
m_{\theta}(x^{i}:\ X)=1 & \longmapsto\text{no preference}\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Estimating Outcomes in the Incentive Space
\end_layout

\begin_layout Standard
Motivated decision making therefore is a two-stage process; the system must
 first create an estimate of the relationship between actions and observations
 of 
\begin_inset Formula $X$
\end_inset

 in the context of those actions and then estimate action values which maximize
 the probability of preferred states given the action's context.
 The first stage can be accomplished using the TI analysis already developed.
 The second stage requries that we apply the motivator to the estimation
 task in a specific context.
 In this case our estimates are no longer probability estimates; instead
 they describe the probability that a given action will correspond to preferred
 states in the context of the action.
 We refer to these estimates as as pints in the incentive space 
\begin_inset Formula $I$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\bar{\varphi}(x:\ X) & \longmapsto\Pr(x|I)\\
\bar{\varphi}(x:\ X) & =\prod_{\upsilon=1}^{d}\sum_{i=1}^{|X|}m_{\theta}(x_{i}^{\nu}:\ X)\beta_{i}\ \bar{K}_{\gamma}(x^{\nu},x_{i}^{\nu},X^{\nu})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Still not sure if the first one makes any sense
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this sense, the motivator function behaves like a weighting mechanism,
 increasing the incentive value of high-probability actions which correspond
 to preferred states and decreasing the incentive value of high-probability
 actions which correspond with discouraged states.
 Estimating values in the incentive space allows us to select actions whose
 influence is well understood to produce the desired states of 
\begin_inset Formula $X$
\end_inset

 in a given context.
 Choosing actions is reduced to determining the supremum of the action dimension
s of the incentive space in a given context.
\end_layout

\begin_layout Subsection
Incentivized Path Search
\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout
This is a work in progress - ignore
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Because estimates can now influence the underlying data, generating estimates
 is no longer a simple matter of perception; the choice of a specific action
 will influence the probability space, making the next estimation task different
 from the last.
 Furthermore, in the context of complex actions made up of multiple vectors,
 the choice of a single action may modify the incentive space independant
 of any influence from the motivator function.
 Maximizing the expected incentive value in a deterministic and computationally
 feasible manner, in the context of these facts, would be of great utility
 and is left as an exercise for the reader.
\end_layout

\begin_layout Standard
We will instead focus on iterative approaches.
 We can create a set of actions 
\begin_inset Formula $A$
\end_inset

 through an iterative process.
 We first define a selector function 
\begin_inset Formula $s(X:\ D)$
\end_inset

 which selects a value of 
\begin_inset Formula $a_{i}$
\end_inset

 from the incentive space defined by 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $D$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
s(X:\ D) & \longmapsto a_{i}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
At each step 
\begin_inset Formula $i+1$
\end_inset

 in the iteration we select a context 
\begin_inset Formula $D$
\end_inset

 and select an action 
\begin_inset Formula $a_{i}=s(X_{i}:\ D)$
\end_inset

 from action dimensions for 
\begin_inset Formula $X_{i}$
\end_inset

 in the given context.
 We then append 
\begin_inset Formula $a_{i}$
\end_inset

 to 
\begin_inset Formula $X_{i}$
\end_inset

 and repeat the process, this time with the set 
\begin_inset Formula $X_{i+1}=X_{i}\cup a_{i}$
\end_inset

.
 
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $s(X:\ D)$
\end_inset

 simply selects the supremum of the action dimensions of 
\begin_inset Formula $X$
\end_inset

, the system is susceptible to local minima.
 Various techniques exist to address this situation; we will simply assume
 that 
\begin_inset Formula $s(X:\ D)$
\end_inset

 is indeterminant and involves some element of randomness.
 This means that at each iteration, multiple values of 
\begin_inset Formula $a_{i}$
\end_inset

are possible.
 We can therefore think of our iterative approach as a tree search, with
 multiple search paths originating from each iteration.
 This leaves us with not simply a set of action paths 
\begin_inset Formula $A$
\end_inset

, but a set of paths, each one tracing a different route from trunk to tip,
 and each one producing different estimates of the expected incentives in
 different contexts.
 This presents yet another problem of choice; which branch of actions should
 actually be taken?
\end_layout

\begin_layout Standard
To address this problem, we define an ethics function 
\begin_inset Formula $e(A_{i})$
\end_inset

.
 The ethics function establishes different weights for different incentive
 values in different contexts:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
e(A_{i}) & \in\mathbb{R}^{+}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We refer to this function as 'ethical' because it makes trade-offs between
 the probability of satisfying the systems motivation and the context to
 which that probability refers; is it better to buy a new car today or save
 my money to buy a house in a year? 
\end_layout

\begin_layout Standard
We can now generate a set of actions which is likely to produce known results
 which will satisfy the system's motivational parameters by selecting the
 supremum of the results of our path search:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
A & =\sup_{A}e(A_{1})\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Curiosity
\end_layout

\begin_layout Standard
Without the ability to take action, a system's accuracy and efficiency for
 a given dataset is limited by the algorithm it uses and the computational
 resources available to it.
 Systems with the ability to influence the observations from which they
 make estimates, on the other hand, can take advantage of this ability to
 increase both their accuracy and performance.
 Before we can discuss the mechanisims by which this is possible, we must
 first develop a more rigorous understanding of these two objectives; accuracy
 and efficiency.
\end_layout

\begin_layout Standard
Any probabilistic system's estimation accuracy is limited by the amount
 of uncertainty inherent in the data it processes and the nature of the
 algorithm used to generate estimates.
 The rate of convergence in such a system's estimations and the 'true' probabili
ty distribution has an upper bound determined by its VC dimension; within
 these bounds a system's estimation accuracy improves as the number of observati
ons increases.
 In the context of TI data, it is possible to think of each neighborhood
 in a TI dimension as an independant estimation problem, thus an observation
 of 
\begin_inset Formula $X$
\end_inset

 will not increase the system's accuracy in a given neighborhood if the
 observation 
\begin_inset Formula $x$
\end_inset

 is not in that neighborhood.
 The task of improving a volitive system's accuracy in a given context therefore
 can be framed as the task of obtaining observations of that context.
 
\end_layout

\begin_layout Standard
The efficiency of the system we've developed is primarily controlled by
 the number of Support Vectors.
 For a given dataset and predictive accuracy, as the number of SV's decreases,
 the efficiency of the system increases.
 The efficiency of non-volitive systems is limited by the results of the
 optimization problem for 
\begin_inset Formula $\beta$
\end_inset

.
 In the context of a volitive system, decreasing the number of SV's can
 be accomplished by obtaining observations higher-order structure.
 Higher-order structure refers to the ability of a multi-layered system
 to break multiple high-entropy observations down into shared combinations
 of lower-entropy observations in such a way that the entropy of combined
 observations is lower than the entropy of the original observations.
 The result of such a process is the ability to eliminate portions of the
 original dataset as redundant, reducing the number of required SV's to
 match the accuracy of the system prior to observing the higher-order structure.
\end_layout

\begin_layout Standard
Working within the context of the existing architecture, our task is to
 develop a metric which can be used as a motivational parameter to drive
 these two behaviors.
 If we assume that the sampling rate of the system is independant of the
 action choices which are made, both behaviors can be reduced to minimizing
 the ratio of observations to support vectors.
 Increasing the system's accuracy can be viewed as determining a suitable
 support vector (or vectors) to represent behavior of 
\begin_inset Formula $X$
\end_inset

 in a given context (allowing the redundant observations to be discarded)
 and promoting the discovery of higher-order structure inherently increases
 this ratio by the same mechanism.
 We can therefore create a curious system by establishing the performance
 metric 
\begin_inset Formula $p(\beta,X)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
p_{|X|}(\beta,X) & =\frac{|X|}{|\beta|-|\beta_{0}|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\beta_{0}=[\beta_{i}|\ \beta_{i}=0]$
\end_inset

.
 Motivating the system towards curiosity simply entails establishing a motivator
 which prefers positive values of the second-derivative of 
\begin_inset Formula $p(\beta,X)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
m(x_{i}^{p}:\ X) & =e^{\lambda\frac{d^{2}}{di^{2}}p_{i}(\beta,X)}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Using the second derivative motivates the system to prefer increases in
 the average change in 
\begin_inset Formula $p(\beta,X)$
\end_inset

.
 The value of 
\begin_inset Formula $p(\beta,X)$
\end_inset

 is likely non-stationary, so establishing a motivational parameter for
 set values isn't helpful.
 The first-derivative of 
\begin_inset Formula $p(\beta,X)$
\end_inset

 establishes the expected change in the system's comprehension, however
 this rate will vary with different datasets and would need to be determined
 for each dataset.
 The second-derivative however describes the rate at which the system's
 comprehension is increasing or decreasing, and is more likely to be tied
 to the system's actions than to the underlying data.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
This needs some housekeeping - explain values of p at each observation and
 work the work 'curiosity' and 'comprehension' into the earlier paragraphs
\end_layout

\end_inset


\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Eunite Competition Data
\end_layout

\begin_layout Subsection
Santa Fe Data
\end_layout

\begin_layout Subsection
CATS Benchmark Data
\end_layout

\begin_layout Subsection
Results Summary
\end_layout

\begin_layout Section
Further Research
\end_layout

\begin_layout Subsection
Data Pre-Processing
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% logistic function using mean and sd to put most training points between
 .1 and .9
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% upper and lower bounds on 
\backslash
(
\backslash
int 
\backslash
Delta 
\backslash
) as non-stationary data detections mechanism
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% logistic function from delta using mean and sd in same way if data non-station
ary
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% iterative integration process until stationary data found ?
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Performance
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
Eat it, bitches
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
nocite{Moreno03}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
bibliographystyle{plain}
\end_layout

\end_inset

 
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "Research/research.bib"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
